{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Operations\n",
    "\n",
    "In TensorFlow, you collectively call constants, variables, operators as ops. TensorFlow is not just a\n",
    "software library, but a suite of softwares that include TensorFlow, TensorBoard, and Tensor Serving.\n",
    "To make the most out of TensorFlow, we should know how to use all of the above in conjunction\n",
    "with one another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a user perform certain operations in a TensorBoard-activated TensorFlow program, these\n",
    "operations are exported to an event log file. TensorBoard is able to convert these event files to\n",
    "visualizations that can give insight into a model's graph and its runtime behavior. Learning to use\n",
    "TensorBoard early and often will make working with TensorFlow much more enjoyable and\n",
    "productive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(2, name = \"a\")\n",
    "b = tf.constant(3, name = \"b\")\n",
    "x = tf.add(a, b, name = \"add\")\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "logdir = './graphs'\n",
    "writer = tf.summary.FileWriter(logdir, graph)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(x))\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualizing with TensorBoard</h1>\n",
    "To visualize the program with TensorBoard, we need to write log files of the program. In order to do so, we first need to create a writer for those logs with\n",
    "<h4><center>writer = tf.summary.FileWriter([logdir], [graph])</center></h4>\n",
    "\n",
    "- **[graph]** is the graph of the program you are working on. You can either call it using tf.get_default_graph(), which returns the default graph of the program, or through sess.graph, which returns the graph the session is handling. The latter requires you to already have created a session. Either way, make sure to create a writer only after you’ve defined your graph, else the graph visualized on TensorBoard would be incomplete.\n",
    "\n",
    "- **[logdir]** is the folder where you want to store those log files. You can choose [logdir] to be something meaningful such as './graphs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "x = tf.add(a, b)\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    # writer = tf.summary.FileWriter('./graphs', sess.graph) # if you prefer creating\n",
    "    # your writer using session's graph\n",
    "    print(sess.run(x))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, go to Terminal, run the program. Make sure that your present working directory is the same as\n",
    "where you ran your Python code.\n",
    "\n",
    "\\$ python3 [filename.py] <br>\n",
    "\\$ tensorboard --logdir=\"./graphs\" --port 6006\n",
    "\n",
    "Open your browser and go to http://localhost:6006/ (or the port of your choice), you will see the\n",
    "TensorBoard page. Go to the Graph tab and you can verify that the graph indeed has 3 nodes, two\n",
    "constants and an Add op."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a tensor of a specific dimension and fill it with a specific value, similar to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# constant of 2x2 tensor (matrix)\n",
    "b = tf.constant([[0, 1], [2, 3]], name=\"matrix\")\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# tf.zeros(shape, dtype = tf.float32, name = None)\n",
    "# create a tensor of shape and all elements are zeros\n",
    "b = tf.zeros([2, 3], tf.int32) # ==> [[0, 0, 0], [0, 0, 0]]\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# tf.ones(shape, dtype = tf.float32, name = None)\n",
    "# create a tensor of shape and all elements are zeros\n",
    "b = tf.ones([2, 3], tf.int32) # ==> [[0, 0, 0], [0, 0, 0]]\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 8 8]\n",
      " [8 8 8]]\n"
     ]
    }
   ],
   "source": [
    "#tf.fill(dims, value, name = None)\n",
    "# create a tensor filled with a scalar value.\n",
    "b = tf.fill(dims = [2, 3],value = 8) \n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating constant as sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 11. 12. 13.]\n"
     ]
    }
   ],
   "source": [
    "#tf.lin_space(start, stop, num, name = None)\n",
    "# create a sequence of num evenly-spaced values are generated beginning at start. If num >\n",
    "# 1, the values in the sequence increase by (stop - start) / (num - 1), so that the last one\n",
    "# is exactly stop.\n",
    "# comparable to but slightly different from numpy.linspace\n",
    "b = tf.lin_space(start = 10.0, stop = 13.0, num = 4, name=\"linspace\") \n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Unlinke numpy sequences, tensorflow sequences are not iterable </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b7c1b545ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m       raise TypeError(\n\u001b[0;32m--> 431\u001b[0;31m           \u001b[0;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    433\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."
     ]
    }
   ],
   "source": [
    "for i in tf.linspace(0.0, 10.0, 4):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Operations\n",
    "Tensorflow maths operations are pretty standard, except for division operations. There are half a duzen types of divisions in tensorflow, so keep in mind to read each one's documentation before using it, but here are a couple of examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 1]]\n",
      "[[0.  0.5]\n",
      " [1.  1.5]]\n",
      "[[0.  0.5]\n",
      " [1.  1.5]]\n",
      "[[0 0]\n",
      " [1 1]]\n",
      "[[0 0]\n",
      " [1 1]]\n",
      "[[0 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([2, 2], name='a')\n",
    "b = tf.constant([[0, 1], [2, 3]], name='b')\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    print(sess.run(tf.div(b, a))) \n",
    "    print(sess.run(tf.divide(b, a))) \n",
    "    print(sess.run(tf.truediv(b, a))) \n",
    "    print(sess.run(tf.floordiv(b, a))) \n",
    "    #print(sess.run(tf.realdiv(b, a))) # ⇒ Error: only works for real values\n",
    "    print(sess.run(tf.truncatediv(b, a))) # ⇒ [[0 0] [1 1]]\n",
    "    print(sess.run(tf.floor_div(b, a))) # ⇒ [[0 0] [1 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[2, 2], \n",
    "                 [1, 1]], name='a')\n",
    "b = tf.constant([[0, 1], \n",
    "                 [2, 3]], name='b')\n",
    "x = tf.add_n([a, b], name = 'add') # => equivalent to a + b + b\n",
    "with tf.Session() as sess:    \n",
    "    print (sess.run(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8 -2]\n",
      " [-8  8]]\n",
      "[[4 0]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[8, 2], \n",
    "                 [4, 2]], name='a')\n",
    "b = tf.constant([[1, -1], \n",
    "                 [-2, 4]], name='b')\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.multiply(a, b))) # ⇒ [20 60] # element-wise multiplication\n",
    "    print(sess.run(tf.tensordot(a, b, 1))) # ⇒ 80 # multiplies matrices of ranks greater or equal to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "Constants have been fun and now is the time to learn about what really matters: variables. The\n",
    "differences between a constant and a variable:\n",
    "- A constant is, well, constant. Often, you’d want your weights and biases to be updated during\n",
    "training.\n",
    "- A constant's value is stored in the graph and replicated wherever the graph is loaded. A variable\n",
    "is stored separately, and may live on a parameter server.\n",
    "\n",
    "The second point means that constants are stored in the graph definition. When constants are memory\n",
    "expensive, such as a weight matrix with millions of entries, it will be slow each time you have to load\n",
    "the graph. To see what’s stored in the graph's definition, simply print out the graph's protobuf.\n",
    "Protobuf stands for protocol buffer, “Google's language-neutral, platform-neutral, extensible\n",
    "mechanism for serializing structured data – think XML, but smaller, faster, and simpler .”\n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"my_const\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 26\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Graph\n",
    "tf.reset_default_graph()\n",
    "my_const = tf.constant([1.0, 2.0], name=\"my_const\")\n",
    "print(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Variables\n",
    "TensorFlow recommends that we use the wrapper\n",
    "tf.get_variable, which allows for easy variable sharing. With tf.get_variable, we can provide variable’s\n",
    "internal name, shape, type, and initializer to give the variable its initial value. Note that when we use\n",
    "tf.constant as an initializer, we don’t need to provide shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "s = tf.get_variable(\"scalar\", initializer=tf.constant(2))\n",
    "m = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\n",
    "W = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())\n",
    "u = tf.get_variable(\"unused_variable\", shape=(784, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to initialize a variable before using it. If you try to evaluate the variables before initializing\n",
    "them you'll run into FailedPreconditionError: Attempting to use uninitialized value. To get a list of\n",
    "uninitialized variables, you can just print them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scalar' 'matrix' 'big_matrix' 'unused_variable']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # To get uninitialized variables:\n",
    "    print(sess.run(tf.report_uninitialized_variables()))\n",
    "    \n",
    "    # The easiest way to initialize all variables is: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    print(sess.run(tf.report_uninitialized_variables()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also initialize each variable separately using tf.Variable.initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scalar' 'matrix' 'big_matrix' 'unused_variable']\n",
      "['scalar' 'matrix' 'unused_variable']\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.report_uninitialized_variables()))\n",
    "    sess.run(W.initializer)\n",
    "    print(sess.run(tf.report_uninitialized_variables()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Values to Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "W = tf.get_variable(\"scalar\", initializer=tf.constant(10))\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print (sess.run(W))\n",
    "\n",
    "# Assigning new value\n",
    "assign_op = W.assign(100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    sess.run(W)\n",
    "    print(W.eval()) # >> 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the cell above, we tried to assign '100' to the W variable by using **W.assign(100)**, but it had no effect. This is because the **assign** method is also an operation, so it has to be run in the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "W = tf.get_variable(\"scalar\", initializer=tf.constant(10))\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print (sess.run(W))\n",
    "\n",
    "assign_op = W.assign(100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Running assign operation\n",
    "    sess.run(assign_op)\n",
    "    sess.run(W)\n",
    "    print(W.eval()) # >> 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple incrementing/decrementing of variables, Tensorflow includes:\n",
    "- tf.Variable.assign_add()\n",
    "- tf.Variable.assign_sub() \n",
    "\n",
    "Unlike tf.Variable.assign(), tf.Variable.assign_add() and tf.Variable.assign_sub() don't initialize your variables for you because these ops depend on the initial values of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "W = tf.Variable(10)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(sess.run(W.assign_add(10))) # >> 20\n",
    "    print(sess.run(W.assign_sub(2))) # >> 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have a variable that depends on another variable, suppose you want to declare U = W * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# W is a random 700 x 10 tensor\n",
    "W = tf.Variable(tf.ones([2, 3]))\n",
    "U = tf.Variable(W * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you should use **initialized_value()** to make sure that W is initialized before its value is used to initialize U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "[[2. 2. 2.]\n",
      " [2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "U = tf.Variable(W.initialized_value() * 2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(W)) # >> 20\n",
    "    print(sess.run(U)) # >> 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data\n",
    "Remember that a TensorFlow program often has 2 phases:\n",
    "\n",
    "- Phase 1: assemble a graph\n",
    "- Phase 2: use a session to execute operations and evaluate variables in the graph\n",
    "\n",
    "We can assemble the graphs first without knowing the values needed for computation. This is\n",
    "equivalent to defining the function of x, y without knowing the values of x, y. For example:\n",
    "\n",
    "<h4><center>f(x, y) = 2x + y</h4></center>\n",
    "\n",
    "x, y are **placeholders** for the actual values. <br>\n",
    "With the graph assembled, we, or our clients, can later supply their own data when they need to\n",
    "execute the computation. To define a placeholder, we use:\n",
    "\n",
    "<h4><center>tf.placeholder(dtype, shape=None, name=None)</h4></center>\n",
    "\n",
    "Dtype, shape, and name are self-explanatory. The only thing to note here is when you set the shape of\n",
    "the placeholder to None. **shape=None means that tensors of any shape will be accepted**. Using\n",
    "shape=None is easy to construct graphs, but nightmarish for debugging. **You should always define the\n",
    "shape of your placeholders as detailed as possible**. shape=None also breaks all following shape inference,\n",
    "which makes many ops not work because they expect certain rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[3]) # a is placeholder for a vector of 3 elements\n",
    "b = tf.constant([5, 5, 5], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.  9. 11.]\n"
     ]
    }
   ],
   "source": [
    "y = 2*x + b # use the placeholder as you would any tensor\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(y, {x: [1, 2, 3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can feed as many data points to the placeholder as we want by iterating through the data set and\n",
    "feed in the value one at a time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#    for a_value in list_of_a_values:\n",
    "#        print(sess.run(c, {a: a_value}))               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can feed values to tensors that aren't placeholders. Any tensors that are feedable can be fed. To\n",
    "check if a tensor is feedable or not, use: \n",
    "\n",
    "<h4><center>tf.Graph.is_feedable(tensor)</center></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(2, 5)\n",
    "b = tf.multiply(a, 3)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(b)) # >> 7*3 = 21\n",
    "    # compute the value of b given the value of a is 15*3 = 15\n",
    "    print(sess.run(b, feed_dict={a: 15})) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
